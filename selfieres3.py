# -*- coding: utf-8 -*-
"""SelfieRes3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H6kNqtHfj7nqzcBDtFyv2KV_uufi2y6C
"""

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d jigrubhatt/selfieimagedetectiondataset

!unzip /content/selfieimagedetectiondataset.zip -d dataset

# import the necessary packages
import os
from os import listdir
from os.path import isfile, join
# initialize the path to the *original* input directory of images
ORIG_INPUT_DATASET = "../content/dataset/Selfie-Image-Detection-Dataset"
# initialize the base path to the *new* directory that will contain
# our images after computing the training and testing split
BASE_PATH = "."


# define the names of the training, testing, and validation
# directories
TRAIN = "Training_data"
TEST = "Test_data"
VAL = "Validation_data"
# initialize the list of class label names
CLASSES = ["Selfie", "NonSelfie"]
# set the batch size
BATCH_SIZE = 32
INIT_LR = 1e-4


# initialize the label encoder file path and the output directory to
# where the extracted features (in CSV file format) will be stored
LE_PATH = os.path.sep.join(["./output", "le.cpickle"])
BASE_CSV_PATH = "./output"
# set the path to the serialized model after training
MODEL_PATH = os.path.sep.join(["./output", "model.cpickle"])

# define the path to the output training history plots
UNFROZEN_PLOT_PATH = os.path.sep.join(["./output", "unfrozen.png"])
WARMUP_PLOT_PATH = os.path.sep.join(["./output", "warmup.png"])

!pip install imutils

# import the necessary packages
from imutils import paths
import shutil
import os
import random
# loop over the data splits
for split in (TRAIN, TEST):
    # grab all image paths in the current split
    print("[INFO] processing '{} split'..................".format(split))
    p = os.path.sep.join([ORIG_INPUT_DATASET, split])
    imagePaths = list(paths.list_images(p))

    # loop over the image paths
    for imagePath in imagePaths:
        # extract class label from the filename
        filename = imagePath.split(os.path.sep)[-1]

        label = imagePath.split(os.path.sep)[-2]
        # construct the path to the output directory
        dirPath = os.path.sep.join([BASE_PATH, split, label])

        # if the output directory does not exist, create it
        if not os.path.exists(dirPath):
            os.makedirs(dirPath)
        # construct the path to the output image file and copy it
        p = os.path.sep.join([dirPath, filename])

        shutil.copy2(imagePath, p)

source = join(BASE_PATH, TEST)#os.path.sep.join([BASE_PATH, TEST])
target = join(BASE_PATH, VAL)

for Type in CLASSES:
    sourcePath = join(source, Type)
    targetPath = join(target, Type)

    if not os.path.exists(targetPath):
        os.makedirs(targetPath)

    print(f"Sourse Path: {sourcePath}\nTarget Path: {targetPath}\n")

    imagePaths = list(paths.list_images(sourcePath))
    random.shuffle(imagePaths)
    mid = int(len(imagePaths) / 2)
    imagePaths = imagePaths[: mid]

    for imagePath in imagePaths:
        filename = imagePath.split(os.path.sep)[-1]

        shutil.copy2(imagePath, join(targetPath,filename))
        os.remove(imagePath)

print(f"Train Data: {len(list(paths.list_images(join(BASE_PATH, TRAIN))))}")
print(f"Validation Data: {len(list(paths.list_images(join(BASE_PATH, VAL))))}")
print(f"Test Data: {len(list(paths.list_images(join(BASE_PATH, TEST))))}")



"""Implementing fine-tuning with Keras"""

# Commented out IPython magic to ensure Python compatibility.
def plot_training(H, N, plotPath):
#     %matplotlib inline
    # construct a plot that plots and saves the training history
    fig, (accuracy, loss) = plt.subplots(1, 2)
    fig.suptitle('Training Loss and Accuracy')
    fig.tight_layout()
    plt.subplots_adjust(wspace = 0.5)
    plt.style.use("ggplot")
    plt.figure()
    loss.plot(np.arange(0, N), H.history["loss"], label="train_loss")
    loss.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
    loss.set_title('Training Loss')
    loss.set_xlabel('Epoch #')
    loss.set_ylabel('Loss')
    loss.legend(loc="upper right")
    accuracy.plot(np.arange(0, N), H.history["accuracy"], label="train_acc")
    accuracy.plot(np.arange(0, N), H.history["val_accuracy"], label="val_acc")
    accuracy.set_title('Training Accuracy')
    accuracy.set_xlabel('Epoch #')
    accuracy.set_ylabel('Accuracy')
    accuracy.legend(loc="lower right")
    fig.savefig(plotPath)

# set the matplotlib backend so figures can be saved in the background
import matplotlib
matplotlib.use("Agg")
# import the necessary packages
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.layers import GlobalAveragePooling2D
from sklearn.metrics import classification_report
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import os

# derive the paths to the training, validation, and testing
# directories
trainPath = os.path.sep.join([BASE_PATH, TRAIN])
valPath = os.path.sep.join([BASE_PATH, VAL])
testPath = os.path.sep.join([BASE_PATH, TEST])
# determine the total number of image paths in training, validation,
# and testing directories
# totalTrain = len(list(paths.list_images(trainPath)))
totalTrain = 10000
totalVal = len(list(paths.list_images(valPath)))
totalTest = len(list(paths.list_images(testPath)))

# initialize the training data augmentation object
trainAug = ImageDataGenerator(
    rotation_range=30,
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    fill_mode="nearest")
# initialize the validation/testing data augmentation object (which
# we'll be adding mean subtraction to)
valAug = ImageDataGenerator()
# define the ImageNet mean subtraction (in RGB order) and set the
# the mean subtraction value for each of the data augmentation
# objects
mean = np.array([123.68, 116.779, 103.939], dtype="float32")
trainAug.mean = mean
valAug.mean = mean

# initialize the training generator
trainGen = trainAug.flow_from_directory(
    trainPath,
    class_mode="categorical",
    target_size=(224, 224),
    color_mode="rgb",
    shuffle=True,
    batch_size=BATCH_SIZE)
# initialize the validation generator
valGen = valAug.flow_from_directory(
    valPath,
    class_mode="categorical",
    target_size=(224, 224),
    color_mode="rgb",
    shuffle=False,
    batch_size=BATCH_SIZE)
# initialize the testing generator
testGen = valAug.flow_from_directory(
    testPath,
    class_mode="categorical",
    target_size=(224, 224),
    color_mode="rgb",
    shuffle=False,
    batch_size=BATCH_SIZE)

# load the VGG16 network, ensuring the head FC layer sets are left
# off
baseModel = VGG16(weights="imagenet", include_top=False, input_tensor=Input(shape=(224, 224, 3)))
# construct the head of the model that will be placed on top of the
# the base model
headModel = baseModel.output
headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(256, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(len(CLASSES), activation="softmax")(headModel)
# place the head FC model on top of the base model (this will become
# the actual model we will train)
model = Model(inputs=baseModel.input, outputs=headModel)

# loop over all layers in the base model and freeze them so they will
# *not* be updated during the first training process
for layer in baseModel.layers:
    layer.trainable = False

import tensorflow as tf

#from keras.optimizers import Adam

# reset our data generators
trainGen.reset()
valGen.reset()

# compile our model (this needs to be done after setting our
# layers to being non-trainable
print("[INFO] compiling model...")
opt = Adam(learning_rate=INIT_LR)  # Remove the 'decay' parameter
model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])
# --------------------------------------------------------
checkpoint_filepath = '/tmp/checkpoint'
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)
# ------------------------------------------------------------
# train the head of the network for a few epochs
print("[INFO] training head...")
H = model.fit(
    x=trainGen,
    steps_per_epoch=totalTrain // BATCH_SIZE,
    validation_data=valGen,
    validation_steps=totalVal // BATCH_SIZE,
    epochs=100,
    callbacks=[model_checkpoint_callback])

# # reset our data generators
# trainGen.reset()
# valGen.reset()

# # compile our model (this needs to be done after our setting our
# # layers to being non-trainable
# print("[INFO] compiling model...")
# opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / 25)
# #opt = SGD(lr=1e-4, momentum=0.9)
# model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])
# # train the head of the network for a few epochs (all other layers
# # are frozen) -- this will allow the new FC layers to start to become
# # initialized with actual "learned" values versus pure random
# print("[INFO] training head...")
# H = model.fit(
#     x=trainGen,
#     steps_per_epoch=totalTrain // BATCH_SIZE,
#     validation_data=valGen,
#     validation_steps=totalVal // BATCH_SIZE,
#     epochs=25)

# reset the testing generator and evaluate the network after
# fine-tuning just the network head
print("[INFO] evaluating after fine-tuning network head...")
testGen.reset()
predIdxs = model.predict(x=testGen, steps=(totalTest // BATCH_SIZE) + 1)
predIdxs = np.argmax(predIdxs, axis=1)
print(classification_report(testGen.classes, predIdxs,target_names=testGen.class_indices.keys()))

if not os.path.exists(BASE_CSV_PATH):
    os.makedirs(BASE_CSV_PATH)
plot_training(H, 100, WARMUP_PLOT_PATH)

# Display The Image
import IPython.display as display
from PIL import Image
display.display(Image.open(WARMUP_PLOT_PATH))

# reset our data generators
trainGen.reset()
valGen.reset()
# now that the head FC layers have been trained/initialized, lets
# unfreeze the final set of CONV layers and make them trainable
for layer in baseModel.layers[:165]:
    layer.trainable = False
for layer in baseModel.layers[165:]:
    layer.trainable = True
# loop over the layers in the model and show which ones are trainable
# or not

for i, layer in enumerate(baseModel.layers):
    print("{}: {}    [{}]".format(i, layer.name, layer.trainable))

# for the changes to the model to take affect we need to recompile
# the model, this time using SGD with a *very* small learning rate
print("[INFO] re-compiling model...")
opt = Adam(learning_rate=INIT_LR)  # Remove the 'decay' parameter
#opt = Adam(lr=INIT_LR, decay=INIT_LR / 25)
#opt = SGD(lr=1e-4, momentum=0.9)
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
# train the model again, this time fine-tuning *both* the final set
# of CONV layers along with our set of FC layers
H = model.fit(
    x=trainGen,
    steps_per_epoch=totalTrain // BATCH_SIZE,
    validation_data=valGen,
    validation_steps=totalVal // BATCH_SIZE,
    epochs=1)

# reset the testing generator and then use our trained model to
# make predictions on the data
print("[INFO] evaluating after fine-tuning network...")
testGen.reset()
predIdxs = model.predict(x=testGen, steps=(totalTest // BATCH_SIZE) + 1)
predIdxs = np.argmax(predIdxs, axis=1)
print(classification_report(testGen.classes, predIdxs, target_names=testGen.class_indices.keys()))
plot_training(H, 5, UNFROZEN_PLOT_PATH)
display.display(Image.open(UNFROZEN_PLOT_PATH))
# serialize the model to disk
print("[INFO] serializing network...")
model.save(MODEL_PATH, save_format="h5")

"""Making predictions with fine-tuning and Keras"""

# import the necessary packages
from tensorflow.keras.models import load_model
import numpy as np
import imutils
import cv2

p = os.path.sep.join([BASE_PATH, TEST])
imagePaths = list(paths.list_images(p))
# load the input image and then clone it so we can draw on it later
image = cv2.imread(imagePaths[2200]) # Image Path
output = image.copy()
output = imutils.resize(output, width=400)
# our model was trained on RGB ordered images but OpenCV represents
# images in BGR order, so swap the channels, and then resize to
# 224x224 (the input dimensions for VGG16)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image = cv2.resize(image, (224, 224))
# convert the image to a floating point data type and perform mean
# subtraction
image = image.astype("float32")
mean = np.array([123.68, 116.779, 103.939][::-1], dtype="float32")
image -= mean

import cv2
from google.colab.patches import cv2_imshow
CLASSES = ["NonSelfie", "Selfie"]

# load the trained model from disk
print("[INFO] loading model...")
model = load_model(MODEL_PATH)
# pass the image through the network to obtain our predictions
preds = model.predict(np.expand_dims(image, axis=0))[0]
print(f"Preds: {preds}")
i = np.argmax(preds)
label = CLASSES[i]
# draw the prediction on the output image
text = "{}: {:.2f}%".format(label, preds[i] * 100)
cv2.putText(output, text, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (15, 30, 255), 2)
# show the output image
cv2_imshow(output)
cv2.waitKey(0)
print("**********")

filename = join('./','savedImage.jpg')
# Using cv2.imwrite() method
# Saving the image
cv2.imwrite(filename, output)

# Display The Image
display.display(Image.open(filename))